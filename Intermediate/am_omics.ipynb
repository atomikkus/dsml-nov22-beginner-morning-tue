{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textwrap import dedent\n",
    "\n",
    "os.makedirs('workflows/nf/sample', exist_ok=True)\n",
    "\n",
    "nf = dedent('''\n",
    "nextflow.enable.dsl = 2\n",
    "\n",
    "params.greeting = 'hello'\n",
    "params.addressee = null\n",
    "\n",
    "if (!params.addressee) exit 1, \"required parameter 'addressee' missing\"\n",
    "\n",
    "process Greet {\n",
    "    publishDir '/mnt/workflow/pubdir'\n",
    "    input:\n",
    "        val greeting\n",
    "        val addressee\n",
    "    \n",
    "    output:\n",
    "        path \"output\", emit: output_file\n",
    "    \n",
    "    script:\n",
    "        \"\"\"\n",
    "        echo \"${greeting} ${addressee}\" | tee output\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "workflow {\n",
    "    Greet(params.greeting, params.addressee)\n",
    "}\n",
    "\n",
    "''').strip()\n",
    "\n",
    "with open('workflows/nf/sample/main.nf', 'wt') as f:\n",
    "    f.write(nf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating workflow zip bundle:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m buffer \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m ZipFile(buffer, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, compression\u001b[39m=\u001b[39mZIP_DEFLATED) \u001b[39mas\u001b[39;00m zf:\n\u001b[1;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39miglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(workflow_root_dir, \u001b[39m'\u001b[39m\u001b[39m**/*\u001b[39m\u001b[39m'\u001b[39m), recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(file):\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=12'>13</a>\u001b[0m             arcname \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreplace(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(workflow_root_dir, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import io\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "\n",
    "# everything in this folder will get bundled into a zip\n",
    "workflow_root_dir = 'workflows/nf/sample/'\n",
    "\n",
    "print(\"creating workflow zip bundle:\")\n",
    "buffer = io.BytesIO()\n",
    "with ZipFile(buffer, mode='w', compression=ZIP_DEFLATED) as zf:\n",
    "    for file in glob.iglob(os.path.join(workflow_root_dir, '**/*'), recursive=True):\n",
    "        if os.path.isfile(file):\n",
    "            arcname = file.replace(os.path.join(workflow_root_dir, ''), '')\n",
    "            print(f\".. adding: {file} -> {arcname}\")\n",
    "            zf.write(file, arcname=arcname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = omics.create_workflow(\n",
    "    name=\"GreetingsNF\",\n",
    "    description=\"Greetings Nextflow workflow\",\n",
    "    definitionZip=buffer.getvalue(),  # this argument needs bytes\n",
    "    main=\"main.nf\",\n",
    "    parameterTemplate={\n",
    "        \"greeting\": {\"description\": \"(string) greeting to use\"},\n",
    "        \"addressee\": {\"description\": \"(string) who to greet\"}\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow_greetings = response\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"waiting for workflow {workflow_greetings['id']} to become ACTIVE\")\n",
    "workflow_greetings = omics.get_workflow(id=workflow_greetings['id'])\n",
    "while workflow_greetings['status'] in ('CREATING', 'UPDATING'):\n",
    "    time.sleep(5)\n",
    "    workflow_greetings = omics.get_workflow(id=workflow_greetings['id'])\n",
    "\n",
    "if workflow_greetings['status'] == 'ACTIVE':\n",
    "    print(f\"workflow {workflow_greetings['id']} ready for use\")\n",
    "else:\n",
    "    print(f\"workflow {workflow_greetings['id']} {workflow_greetings['status']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_uri = \"s3://aws-genomics-static-us-east-1/omics-workshop/gatkbestpractices.wdl.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"sample_name\": {\"description\": \"sample name\"},\n",
    "    \"fastq_1\": {\"description\": \"path to fastq1\"},\n",
    "    \"fastq_2\": {\"description\": \"path to fastq2\"},\n",
    "    \"ref_fasta\": {\"description\": \"path to reference fasta\"},\n",
    "    \"readgroup_name\": {\"description\": \"readgroup name\"},\n",
    "    \"library_name\": {\"description\": \"library name\"},\n",
    "    \"platform_name\": {\"description\": \"platform name, e.g. Illumina\"},\n",
    "    \"run_date\": {\"description\": \"sequencing run date\"},\n",
    "    \"sequencing_center\": {\"description\": \"name of sequencing center\"},\n",
    "    \"dbSNP_vcf\": {\"description\": \"dbsnp vcf\"},\n",
    "    \"Mills_1000G_indels_vcf\": {\"description\": \"Mills 1000 genomes gold indels vcf\"},\n",
    "    \"known_indels_vcf\": {\"description\": \"known indels vcf\"},\n",
    "    \"scattered_calling_intervals_archive\": {\"description\": \"tar gzip of scatter intervals\"},\n",
    "    \"gatk_docker\": {\"description\": \"docker uri in private ECR of GATK\"},\n",
    "    \"gotc_docker\": {\"description\": \"docker uri in private ECR of Genomes in the Cloud\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = omics.create_workflow(\n",
    "    name=\"GATK\",\n",
    "    description=\"GATK best practices variant discovery\",\n",
    "    definitionUri=definition_uri,  \n",
    "    main=\"main.wdl\",\n",
    "    parameterTemplate=parameters,\n",
    ")\n",
    "\n",
    "workflow_gatk = response\n",
    "\n",
    "print(f\"waiting for workflow {workflow_gatk['id']} to become ACTIVE\")\n",
    "workflow_gatk = omics.get_workflow(id=workflow_gatk['id'])\n",
    "while workflow_gatk['status'] in ('CREATING', 'UPDATING'):\n",
    "    time.sleep(5)\n",
    "    workflow_gatk = omics.get_workflow(id=workflow_gatk['id'])\n",
    "\n",
    "if workflow_gatk['status'] == 'ACTIVE':\n",
    "    print(f\"workflow {workflow_gatk['id']} ready for use\")\n",
    "else:\n",
    "    print(f\"workflow {workflow_gatk['id']} {workflow_gatk['status']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Worlflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = omics.start_run(\n",
    "    workflowId=workflow_greetings['id'],\n",
    "    name=\"Greetings workflow run\",\n",
    "    roleArn=OMICS_JOB_ROLE_ARN,\n",
    "    parameters={\n",
    "        \"greeting\": \"Hello\", \n",
    "        \"addressee\": \"Amazon\"},\n",
    "    outputUri=f's3://{OMICS_OUTPUT_BUCKET}/output/greetings',\n",
    ")\n",
    "\n",
    "run_greetings = response\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_greetings = omics.get_run(id=run_greetings['id'])\n",
    "run_greetings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_name = 'NA12878_20K'\n",
    "gatk_container_uri = f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/gatk:4.1.9.0\"\n",
    "gotc_container_uri = f\"{AWS_ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/genomes-in-the-cloud:2.4.7-1603303710\"\n",
    "\n",
    "response = omics.start_run(\n",
    "    workflowId=workflow_gatk['id'],\n",
    "    name=f\"GATK variant discovery - {sample_name}\",\n",
    "    roleArn=OMICS_JOB_ROLE_ARN,\n",
    "    parameters={\n",
    "        \"sample_name\": sample_name,\n",
    "        \"fastq_1\": f\"s3://{OMICS_WORKSHOP_BUCKET}/data/fastq/GIAB_NIST_NA12878_HG001_HiSeq_300x__L002_R1_001.fastq.gz\",\n",
    "        \"fastq_2\": f\"s3://{OMICS_WORKSHOP_BUCKET}/data/fastq/GIAB_NIST_NA12878_HG001_HiSeq_300x__L002_R2_001.fastq.gz\",\n",
    "        \"ref_fasta\": \"s3://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\",\n",
    "        \"readgroup_name\": \"NA12878\",\n",
    "        \"library_name\": \"Solexa-NA12878\",\n",
    "        \"platform_name\": \"Illumina\",\n",
    "        \"run_date\": \"2016-09-01T02:00:00+0200\",\n",
    "        \"sequencing_center\": \"ABCD\",\n",
    "        \"ref_fasta\": \"s3://broad-references/hg38/v0/Homo_sapiens_assembly38.fasta\",\n",
    "        \"dbSNP_vcf\": \"s3://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf\",\n",
    "        \"Mills_1000G_indels_vcf\": \"s3://broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz\",\n",
    "        \"known_indels_vcf\": \"s3://broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz\",\n",
    "        \"scattered_calling_intervals_archive\": f\"s3://{OMICS_WORKSHOP_BUCKET}/intervals.tar.gz\",\n",
    "        \"gatk_docker\": gatk_container_uri,\n",
    "        \"gotc_docker\": gotc_container_uri\n",
    "    },\n",
    "    outputUri=f's3://{OMICS_OUTPUT_BUCKET}/output/gatk',\n",
    ")\n",
    "\n",
    "run_gatk = response\n",
    "response\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
